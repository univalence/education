{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul distribué (Map-Reduce Spark) - ESIPE, \"INFO 3-Opt° Logiciel\"\n",
    "# Evaluation 2019-2020\n",
    "<style type=\"text/css\">\n",
    "    .question {\n",
    "        background-color: yellow;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this evaluation, we will analyse the parking meters of Paris for the year 2014. The dataset is composed in two parts:\n",
    "* The parking meter devices\n",
    "* The transactions\n",
    "\n",
    "All the data needed for this evaluation are located in the directory `data`.\n",
    "\n",
    "### Evaluation process\n",
    "\n",
    "This notebook is divided in 5 parts:\n",
    "* PART 1: Initiate the environment (/1)\n",
    "* PART 2: Get and analyse the device dataset (/3)\n",
    "* PART 3: Get and analyse the transaction dataset (/7)\n",
    "* PART 4: Joining devices and transactions (/5)\n",
    "* PART 5: Analytics on a map (/4)\n",
    "\n",
    "All questions are highlight in <span style=\"background-color: yellow\">yellow</span>. They have to be answered using Spark Core / SQL / ML features. Indicative rating is given for each question (total / 20). Task answers, code clarity and good use of spark computing possibilities are taking into account for the final rating.\n",
    "\n",
    "During this evaluation, you can access to any support including internet, course lectures and labs. the use of online messaging and drives are not permitted during this session.\n",
    "\n",
    "<span style=\"background-color: #ffbbaa;\">**Do not forget to oftenly save your whole notebook.**</span>\n",
    "\n",
    "At the end of the session, rename the notebook with the following format `\"evaluation_<name>.ipynb\"`. Then, send it by email at `francois@univalence.io; bernarith@univalence.io`. Wait for the examiners notebook approval before leaving the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Initiate the environment (/1)\n",
    "To do our analysis, we will use Spark SQL.\n",
    "\n",
    "<span style=\"background-color: yellow;\">Create a SparkSession and assign it to the variable `spark`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@c9d0cba\n",
       "sc = org.apache.spark.SparkContext@46ba03db\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@46ba03db"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder\n",
    "    .appName(\"ParkingMetterAnalytics\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "val sc = spark.sparkContext\n",
    "\n",
    "println(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, the Spark UI interface is available at http://localhost:4040/ or  http://localhost:4041/.\n",
    "\n",
    "We will need also many Spark SQL tools. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Get and analyse the device dataset (/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read parking meter files (/0.5)\n",
    "The parking meter devices are stored in a JSON file of 4.5MB.\n",
    "\n",
    "<span style=\"background-color: yellow;\">Read file `data/horodateurs-mobiliers.json` and store it in a variable named `raw_parkmeters`. Display its content by using the method `.show()`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           datasetid|              fields|            geometry|    record_timestamp|            recordid|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|horodateurs-mobil...|[18 RUE DU GENERA...|[[2.2621510006342...|2019-07-26T14:20:...|2ac791554242ed16b...|\n",
      "|horodateurs-mobil...|[44 AVENUE GEORGE...|[[2.2799760006304...|2019-07-26T14:20:...|29eb91e68c848e4a4...|\n",
      "|horodateurs-mobil...|[6 RUE GIFFARD, S...|[[2.3725550003135...|2019-07-26T14:20:...|aa09cbb9d1e7cd8d6...|\n",
      "|horodateurs-mobil...|[13 bis RUE FELIX...|[[2.4105978799268...|2019-07-26T14:20:...|5f959c793e8aa2865...|\n",
      "|horodateurs-mobil...|[3 RUE LOUIS LOUC...|[[2.3258659994146...|2019-07-26T14:20:...|fc6e0c7d81b7051e7...|\n",
      "|horodateurs-mobil...|[3 vis-à-vis RUE ...|[[2.3585040002808...|2019-07-26T14:20:...|17fd1a8389f9c1050...|\n",
      "|horodateurs-mobil...|[25 RUE DES MATHU...|[[2.3260039997282...|2019-07-26T14:20:...|cf0334249e4544767...|\n",
      "|horodateurs-mobil...|[5 RUE MERLIN, SO...|[[2.3858520000669...|2019-07-26T14:20:...|b06812510ef6ee41f...|\n",
      "|horodateurs-mobil...|[28 RUE MICHEL AN...|[[2.2625229998967...|2019-07-26T14:20:...|8b37478dd1274bb6c...|\n",
      "|horodateurs-mobil...|[8 RUE MONGE, PIL...|[[2.3494480006440...|2019-07-26T14:20:...|1815afa044b271200...|\n",
      "|horodateurs-mobil...|[53 RUE MONSIEUR ...|[[2.3404080006266...|2019-07-26T14:20:...|5b6e0f1d58e63a41c...|\n",
      "|horodateurs-mobil...|[19 RUE DU CHATEA...|[[2.3706660001120...|2019-07-26T14:20:...|95ca00cf8c4f1eb10...|\n",
      "|horodateurs-mobil...|[12 RUE CLAUDE DE...|[[2.2892250004576...|2019-07-26T14:20:...|3ad4742143f3df489...|\n",
      "|horodateurs-mobil...|[37 RUE DE CLICHY...|[[2.3292869994700...|2019-07-26T14:20:...|009a0a69218f447ae...|\n",
      "|horodateurs-mobil...|[39 RUE DE CONSTA...|[[2.3172210001107...|2019-07-26T14:20:...|a5d64d5aa20169ac6...|\n",
      "|horodateurs-mobil...|[18 terre-plein v...|[[2.3576640002058...|2019-07-26T14:20:...|080f5e2a7ff04cd26...|\n",
      "|horodateurs-mobil...|[58 AVENUE D IENA...|[[2.2958599993524...|2019-07-26T14:20:...|433e1c8ba6c15d8d4...|\n",
      "|horodateurs-mobil...|[11 AVENUE JEAN M...|[[2.3254839996108...|2019-07-26T14:20:...|fccd3bbbb683c0786...|\n",
      "|horodateurs-mobil...|[5 RUE LE CHATELI...|[[2.2956090003525...|2019-07-26T14:20:...|a87a7494a3efe6308...|\n",
      "|horodateurs-mobil...|[17 RUE BROCHANT,...|[[2.3176550001683...|2019-07-26T14:20:...|9f221fe517fb07624...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "raw_parkmeters = [datasetid: string, fields: struct<adresse: string, alim: string ... 10 more fields> ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[datasetid: string, fields: struct<adresse: string, alim: string ... 10 more fields> ... 3 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read \"data/horodateurs-mobiliers.json\"\n",
    "val raw_parkmeters = spark.read.json(\"data/horodateurs-mobiliers.json\")\n",
    "raw_parkmeters.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display schema (/0.5)\n",
    "The file comes with nested records. We will need to simplify its structure.\n",
    "\n",
    "To understand its structure, <span style=\"background-color: yellow;\">display the schema of `raw_parkmeters`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datasetid: string (nullable = true)\n",
      " |-- fields: struct (nullable = true)\n",
      " |    |-- adresse: string (nullable = true)\n",
      " |    |-- alim: string (nullable = true)\n",
      " |    |-- arrondt: long (nullable = true)\n",
      " |    |-- geo_point_2d: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- geo_shape: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- modele: string (nullable = true)\n",
      " |    |-- numhoro: long (nullable = true)\n",
      " |    |-- objectid: long (nullable = true)\n",
      " |    |-- regime: string (nullable = true)\n",
      " |    |-- tarif: string (nullable = true)\n",
      " |    |-- tarifhor: double (nullable = true)\n",
      " |    |-- zoneres: string (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- record_timestamp: string (nullable = true)\n",
      " |-- recordid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_parkmeters.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify dataframe (/2)\n",
    "We are here interested only on those fields:\n",
    "* `numhoro`: parking meter number (it must be renamed to `parkmeter_id`)\n",
    "* `arrondt`: district number in Paris (it must be renamed to `district`)\n",
    "* `regime`: pricing mode (MIX = includes specific rule for inhabitants (_résident_), ROT = everyone follows the same rules - it must be renamed `type`)\n",
    "* `zoneres`: residential area (it must be renamed to `area`)\n",
    "\n",
    "<span style=\"background-color: yellow;\">Create a new dataframe from `raw_parkmeters` named `parkmeters`, that includes only the fields shown above.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parkmeters = [parkmeter_id: bigint, district: bigint ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[parkmeter_id: bigint, district: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parkmeters = raw_parkmeters.select(\n",
    "    col(\"fields.numhoro\").alias(\"parkmeter_id\"),\n",
    "    col(\"fields.arrondt\").alias(\"district\"),\n",
    "    col(\"fields.zoneres\").alias(\"area\"),\n",
    "    col(\"fields.regime\").alias(\"type\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: Get and analyse the transaction dataset (/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all the files (/0.5)\n",
    "<span style=\"background-color: yellow;\">Read all the files in `data/horodateurs-transactions-de-paiement` directory in a single command to create a dataframe named `raw_transactions`.</span>\n",
    "\n",
    "Pay attention to the fact that there is a header in the files and that the semi-colon (`;`) is used as a field delimiter. For the last one, we will use the option `.option(\"delimiter\", \";\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_transactions = [horodateur: string, date horodateur: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[horodateur: string, date horodateur: string ... 6 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw_transactions = spark.read\n",
    "  .option(\"delimiter\", \";\")\n",
    "  .option(\"header\", true)\n",
    "  .csv(\"data/horodateurs-transactions-de-paiement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the content (/0.5)\n",
    "<span style=\"background-color: yellow;\">Display its content by using the method `.show()`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------+-----------------+-------------+---------------+-------------------+-------------------+\n",
      "|horodateur|date horodateur    |usager  |moyen de paiement|montant carte|dur�e pay�e (h)|d�but stationnement|fin stationnement  |\n",
      "+----------+-------------------+--------+-----------------+-------------+---------------+-------------------+-------------------+\n",
      "|1050      |31/01/2014 15:09:33|R�sident|CB               |3,25         |50,00          |31/01/2014 15:09:33|07/02/2014 15:09:33|\n",
      "|1050      |24/01/2014 13:41:24|Rotatif |CB               |0,90         |0,25           |24/01/2014 13:41:24|24/01/2014 13:56:24|\n",
      "|20301     |21/01/2014 23:56:27|R�sident|CB               |0,65         |10,00          |21/01/2014 23:56:27|22/01/2014 19:00:00|\n",
      "|20301     |23/01/2014 22:51:32|R�sident|CB               |0,65         |10,00          |23/01/2014 22:51:32|24/01/2014 19:00:00|\n",
      "|20301     |27/01/2014 07:45:12|R�sident|CB               |0,65         |10,00          |27/01/2014 07:45:12|27/01/2014 19:00:00|\n",
      "|20301     |28/01/2014 22:11:10|R�sident|CB               |0,65         |10,00          |28/01/2014 22:11:10|29/01/2014 19:00:00|\n",
      "|20301     |23/01/2014 09:24:10|R�sident|CB               |3,25         |50,00          |23/01/2014 09:24:10|30/01/2014 09:24:10|\n",
      "|20301     |25/01/2014 14:54:28|R�sident|CB               |3,25         |50,00          |25/01/2014 14:54:28|31/01/2014 19:00:00|\n",
      "|20301     |26/01/2014 19:21:09|R�sident|CB               |3,25         |50,00          |26/01/2014 19:21:09|31/01/2014 19:00:00|\n",
      "|20301     |26/01/2014 20:04:37|R�sident|CB               |3,25         |50,00          |26/01/2014 20:04:37|31/01/2014 19:00:00|\n",
      "|20301     |28/01/2014 09:15:22|R�sident|CB               |3,25         |50,00          |28/01/2014 09:15:22|04/02/2014 09:15:22|\n",
      "|20301     |30/01/2014 09:31:50|R�sident|CB               |3,25         |50,00          |30/01/2014 09:31:50|06/02/2014 09:31:50|\n",
      "|20301     |31/01/2014 19:51:13|R�sident|CB               |3,25         |50,00          |31/01/2014 19:51:13|07/02/2014 19:00:00|\n",
      "|20301     |23/01/2014 08:29:21|R�sident|Paris Carte      |0,65         |10,00          |23/01/2014 08:29:21|23/01/2014 19:00:00|\n",
      "|20301     |24/01/2014 14:27:53|R�sident|Paris Carte      |0,65         |10,00          |24/01/2014 14:27:53|27/01/2014 14:27:53|\n",
      "|20301     |27/01/2014 04:29:03|R�sident|Paris Carte      |0,65         |10,00          |27/01/2014 04:29:03|27/01/2014 19:00:00|\n",
      "|20301     |27/01/2014 19:53:43|R�sident|Paris Carte      |0,65         |10,00          |27/01/2014 19:53:43|28/01/2014 19:00:00|\n",
      "|20301     |29/01/2014 06:53:11|R�sident|Paris Carte      |0,65         |10,00          |29/01/2014 06:53:11|29/01/2014 19:00:00|\n",
      "|20301     |29/01/2014 12:07:46|R�sident|Paris Carte      |0,65         |10,00          |29/01/2014 12:07:46|30/01/2014 12:07:46|\n",
      "|20301     |29/01/2014 20:34:07|R�sident|Paris Carte      |0,65         |10,00          |29/01/2014 20:34:07|30/01/2014 19:00:00|\n",
      "+----------+-------------------+--------+-----------------+-------------+---------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_transactions.show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: here `usager` are the users of parking meters. They can be Résident (or `R�sident`), if they are inhabitants. They can be `Rotatif`, if they are considered as occasional visitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The schema (/0.5)\n",
    "<span style=\"background-color: yellow;\">Now, display the schema of the dataset.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- horodateur: string (nullable = true)\n",
      " |-- date horodateur: string (nullable = true)\n",
      " |-- usager: string (nullable = true)\n",
      " |-- moyen de paiement: string (nullable = true)\n",
      " |-- montant carte: string (nullable = true)\n",
      " |-- dur�e pay�e (h): string (nullable = true)\n",
      " |-- d�but stationnement: string (nullable = true)\n",
      " |-- fin stationnement: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_transactions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning (/5)\n",
    "The dataset comes with some inconveniences:\n",
    "* Everything is a string in this schema\n",
    "* Some columns have name with strange characters\n",
    "* Numbers are in French format\n",
    "* Timestamps are in french format too\n",
    "\n",
    "To improve the dataset, we will provide two functions:\n",
    "* `toDouble` that takes a column representing a number, replace \",\" by \".\" and cast it into DoubleType (you will need the Spark SQL function `translate`)\n",
    "* `toTimestamp` that takes a column representing a timestamp with the format `\"dd/MM/yyyy HH:mm:ss\"` and convert it Unix timestamp (you will need the Spark SQL function `unix_timestamp` with two parameters). A Unix timestamp is in seconds.\n",
    "\n",
    "But first, let run the cell below, that creates a function to simplify the writing of unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_function: (function: org.apache.spark.sql.Column => org.apache.spark.sql.Column, de: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_function(function : (Column => Column), de : DataFrame): Unit = {\n",
    "        val text_df = de.toDF(\"data\", \"expected\")\n",
    "        val result = text_df\n",
    "          .withColumn(\"result\", function(col(\"data\")))\n",
    "          .withColumn(\"succeed\", col(\"expected\") === col(\"result\"))\n",
    "        result.show()\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDouble function (/1)\n",
    "<span style=\"background-color: yellow;\">Complete the function `toDouble`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+\n",
      "|data|expected|result|succeed|\n",
      "+----+--------+------+-------+\n",
      "| 1,0|     1.0|   1.0|   true|\n",
      "| 3,4|     3.4|   3.4|   true|\n",
      "|0,65|    0.65|  0.65|   true|\n",
      "+----+--------+------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data_expected = [_1: string, _2: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<console>:37: error: missing argument list for method test_function\n",
       "Unapplied methods are only converted to functions when a function type is expected.\n",
       "You can make this conversion explicit by writing `test_function _` or `test_function(_,_)` instead of `test_function`.\n",
       "       test_function\n",
       "       ^\n",
       "lastException: Throwable = null\n",
       "toDouble: (column: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_1: string, _2: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toDouble(column: Column): Column = {\n",
    "        translate(column, \",\", \".\").cast(DoubleType)\n",
    "      }\n",
    "\n",
    "// Unit test\n",
    "val data_expected = Seq(\n",
    "    (\"1,0\", 1.0),\n",
    "    (\"3,4\", 3.4),\n",
    "    (\"0,65\", 0.65)\n",
    ").toDF()\n",
    "test_function(toDouble, data_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToTimestamp function (/1)\n",
    "<span style=\"background-color: yellow;\">Complete the function `toTimestamp`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------+\n",
      "|               data|  expected|    result|succeed|\n",
      "+-------------------+----------+----------+-------+\n",
      "|31/01/2014 15:09:33|1391180973|1391180973|   true|\n",
      "|24/01/2014 13:56:24|1390571784|1390571784|   true|\n",
      "|26/01/2014 19:21:09|1390764069|1390764069|   true|\n",
      "+-------------------+----------+----------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data_expected = [_1: string, _2: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "toTimestamp: (column: org.apache.spark.sql.Column)org.apache.spark.sql.Column\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_1: string, _2: int]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toTimestamp(column: Column): Column = {\n",
    "    unix_timestamp(column, \"dd/MM/yyyy HH:mm:ss\")    \n",
    "}\n",
    "\n",
    "// Unit tests\n",
    "val data_expected = Seq(\n",
    "    (\"31/01/2014 15:09:33\", 1391180973),\n",
    "    (\"24/01/2014 13:56:24\", 1390571784),\n",
    "    (\"26/01/2014 19:21:09\", 1390764069)\n",
    ").toDF\n",
    "test_function(toTimestamp, data_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning process (/3)\n",
    "Now do the cleaning:\n",
    "* `horodateur` needs to be renamed into `parkmeter_id`\n",
    "* `montant carte` needs to be converted into number and renamed `amount`\n",
    "* `d�but stationnement` needs to be converted into timestamp and renamed `parking_start`\n",
    "* `fin stationnement` needs to be converted into timestamp and renamed `parking_end`\n",
    "\n",
    "You will also add a column `duration`, that is the result of the difference between `parking_start` and `parking_end`. Make sure that `duration` is in hours, knowing that `parking_start` and `parking_end` are in seconds.\n",
    "\n",
    "We only want transactions for users marked as `Rotatif`.\n",
    "\n",
    "<span style=\"background-color: yellow;\">Starts from `raw_transactions` and apply all the cleaning rules seen above to create the dataframe `transactions`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transactions = [parkmeter_id: string, amount: double ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[parkmeter_id: string, amount: double ... 4 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val transactions = raw_transactions\n",
    "    .withColumn(\"parking_start\", toTimestamp(col(\"d�but stationnement\")))\n",
    "    .withColumn(\"parking_end\", toTimestamp(col(\"fin stationnement\")))\n",
    ".select(\n",
    "        col(\"horodateur\").alias(\"parkmeter_id\"),\n",
    "        toDouble(col(\"montant carte\")).alias(\"amount\"),\n",
    "        toDouble(col(\"dur�e pay�e (h)\")).alias(\"payed_duration\"),\n",
    "        col(\"parking_start\"),\n",
    "        col(\"parking_end\"),\n",
    "        ((col(\"parking_end\") - col(\"parking_start\")) / (60.0 * 60.0)).alias(\"duration\")\n",
    ").where(col(\"usager\") === \"Rotatif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow;\">Use `.show()` method to display the content of `transactions`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------+-------------+-----------+------------------+\n",
      "|parkmeter_id|amount|payed_duration|parking_start|parking_end|          duration|\n",
      "+------------+------+--------------+-------------+-----------+------------------+\n",
      "|        1050|   0.9|          0.25|   1390570884| 1390571784|              0.25|\n",
      "|       20301|   0.9|          0.25|   1390570800| 1390571700|              0.25|\n",
      "|       20301|   0.9|          0.25|   1390832331| 1390833231|              0.25|\n",
      "|       20301|   0.9|          0.25|   1391089833| 1391090733|              0.25|\n",
      "|       20301|   0.9|          0.25|   1391188067| 1391188967|              0.25|\n",
      "|       20301|   0.9|          0.25|   1391189808| 1391190708|              0.25|\n",
      "|       20301|   1.8|           0.5|   1390401545| 1390403345|               0.5|\n",
      "|       20301|   1.8|           0.5|   1390556079| 1390557879|               0.5|\n",
      "|       20301|   1.8|           0.5|   1391105707| 1391107507|               0.5|\n",
      "|       20301|   2.7|          0.75|   1390923166| 1390925866|              0.75|\n",
      "|       20301|   2.7|          0.75|   1390990118| 1390992818|              0.75|\n",
      "|       20301|   3.6|           1.0|   1390410522| 1390414122|               1.0|\n",
      "|       20301|   3.6|           1.0|   1390477155| 1390480755|               1.0|\n",
      "|       20301|   3.6|           1.0|   1390811529| 1390816800|1.4641666666666666|\n",
      "|       20301|   4.5|          1.25|   1390404750| 1390409250|              1.25|\n",
      "|       20301|   4.5|          1.25|   1390492174| 1390496674|              1.25|\n",
      "|       20301|   4.5|          1.25|   1390576235| 1390580735|              1.25|\n",
      "|       20301|   4.5|          1.25|   1390926170| 1390930670|              1.25|\n",
      "|       20301|   4.5|          1.25|   1390926626| 1390931126|              1.25|\n",
      "|       20301|   4.5|          1.25|   1391009010| 1391013510|              1.25|\n",
      "+------------+------+--------------+-------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of records (/0.5)\n",
    "\n",
    "<span style=\"background-color: yellow;\">Display the number of records in `transactions`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19033897"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4: Joining devices and transactions (/5)\n",
    "Now that we have the devices location and the transactions, we can merge those two datasets and do different analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining (/2)\n",
    "<span style=\"background-color: yellow;\">Create a dataframe named `parkmeter_transactions`, that joins the dataframes `parkmeters` and `transactions`.</span>\n",
    "\n",
    "* Keep only those columns: `\"parkmeter_id\", \"district\", \"area\", \"duration\", \"parking_start\", \"parking_end\", \"amount\"`\n",
    "* Beware! some columns are defined both in `transactions` and in `parkmeters`. Depending, on the way you reference a column, it can lead Spark to confusion and thus a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parkmeter_transactions = [parkmeter_id: string, district: bigint ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[parkmeter_id: string, district: bigint ... 5 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parkmeter_transactions =\n",
    "// transactions.join(parkmeters, transactions(\"parkmeter_id\") === parkmeters(\"parkmeter_id\"))\n",
    "transactions.join(parkmeters, \"parkmeter_id\")\n",
    "    .select(\n",
    "        transactions(\"parkmeter_id\"),\n",
    "        $\"district\",\n",
    "        $\"area\",\n",
    "        $\"duration\",\n",
    "        $\"parking_start\",\n",
    "        $\"parking_end\",\n",
    "        $\"amount\")\n",
    "// transactions.parkmeter_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the join (/1)\n",
    "Before going further, due to the size of the data, the relative heaviness of the processing, and the weakness of the machine you are working on, it is preferable to store data in a Parquet file first.\n",
    "\n",
    "Once written, this file will be used as a checkpoint. So, **if something goes wrong in your notebook, you can start again from the read of the parquet file below.**\n",
    "\n",
    "<span style=\"background-color: yellow;\">Store the `parkmeter_transactions` dataframe in the Parquet file `parkmeter_transactions.parquet`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkmeter_transactions.write.mode(\"overwrite\").parquet(\"parkmeter_transactions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow;\">Now load the file in `parkmeter_transactions`.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parkmeter_transactions = [parkmeter_id: string, district: bigint ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[parkmeter_id: string, district: bigint ... 5 more fields]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parkmeter_transactions = spark.read.parquet(\"parkmeter_transactions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First analysis of parkmeter_transactions (/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do an analysis of dataframe `parkmeter_transactions`. For that we will use the method `.describe()` available on dataframes. `.describe()` returns a dataframe with stats on the different columns.\n",
    "\n",
    "<span style=\"background-color: yellow;\">Use `.describe()` on `parkmeter_transactions` and display its result.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>summary</th><th>parkmeter_id</th><th>district</th><th>area</th><th>duration</th><th>parking_start</th><th>parking_end</th><th>amount</th></tr><tr><td>count</td><td>18880331</td><td>18880331</td><td>18880331</td><td>18137113</td><td>18880331</td><td>18137113</td><td>18880331</td></tr><tr><td>mean</td><td>5.0660524602441505E7</td><td>12.701171976275203</td><td>13.944135404050764</td><td>2.874938438858208</td><td>1.4038905757585852E9</td><td>1.4034730421784124E9</td><td>2.6736536404118287</td></tr><tr><td>stddev</td><td>2.8897308100392148E7</td><td>4.6756002880304575</td><td>7.552287449180098</td><td>8.855951946794098</td><td>9307864.260225637</td><td>9248501.709550656</td><td>1.864034619949784</td></tr><tr><td>min</td><td>10030101</td><td>1</td><td>10E</td><td>0.004166666666666667</td><td>1388534441</td><td>1388653275</td><td>0.0</td></tr><tr><td>max</td><td>99980113</td><td>20</td><td>9G</td><td>760.0</td><td>1420070214</td><td>1420196400</td><td>7.2</td></tr></table>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dataframe\n",
    "parkmeter_transactions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|parking_end|\n",
      "+-----------+\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "|       null|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parkmeter_transactions.select($\"parking_end\").orderBy(\"parking_end\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `count` row shows the number of non-null elements for each column.\n",
    "\n",
    "What can you identify from the result of `.describe()`?\n",
    "\n",
    "<span style=\"background-color: yellow;\">Update `parkmeter_transactions` to remove rows with undesirable values.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parkmeter_transactions_updated = [parkmeter_id: string, district: bigint ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[parkmeter_id: string, district: bigint ... 5 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parkmeter_transactions_updated = parkmeter_transactions.where(col(\"parking_end\").isNotNull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 5: Analytics (/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of transactions (/2)\n",
    "<span style=\"background-color: yellow;\">Find the number of transactions per district on the map of Paris, the columns must be \"district\" and \"count_transactions\".</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|district|count_transactions|\n",
      "+--------+------------------+\n",
      "|       1|            217918|\n",
      "|       2|            150775|\n",
      "|       3|            332353|\n",
      "|       4|            297668|\n",
      "|       5|            671297|\n",
      "|       6|            522417|\n",
      "|       7|            844408|\n",
      "|       8|           1224097|\n",
      "|       9|            641778|\n",
      "|      10|            418927|\n",
      "|      11|            918664|\n",
      "|      12|           1181645|\n",
      "|      13|           1612113|\n",
      "|      14|           1278967|\n",
      "|      15|           1861138|\n",
      "|      16|           2023056|\n",
      "|      17|           1447280|\n",
      "|      18|            775634|\n",
      "|      19|            844784|\n",
      "|      20|            872194|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count_transactions = [district: bigint, count_transactions: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[district: bigint, count_transactions: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val count_transactions = parkmeter_transactions_updated\n",
    " .groupBy(\"district\")\n",
    " .agg(count(lit(1))\n",
    "   .alias(\"count_transactions\"))\n",
    "\n",
    "count_transactions.orderBy(\"district\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow;\">Find the number of transactions per area on the map of Paris, the columns must be \"area\" and \"count_transactions\".</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|area|count_transactions|\n",
      "+----+------------------+\n",
      "| 20E|             59020|\n",
      "| 17R|            195511|\n",
      "| 13G|             96797|\n",
      "| 17H|            143629|\n",
      "| 14G|             89070|\n",
      "| 16H|             83797|\n",
      "| 12K|             80208|\n",
      "|  2E|            150775|\n",
      "| 16W|            113714|\n",
      "| 20L|             69274|\n",
      "| 11G|            155370|\n",
      "| 17F|            162810|\n",
      "| 11L|            178897|\n",
      "| 15M|            146438|\n",
      "| 19L|             79961|\n",
      "| 16I|            102528|\n",
      "| 20H|            135256|\n",
      "| 18H|             37052|\n",
      "| 14N|            261768|\n",
      "|  7E|            133919|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count_transactions = [area: string, count_transactions: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[area: string, count_transactions: bigint]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val count_transactions = parkmeter_transactions_updated.groupBy(\"area\").agg(count(lit(1)).alias(\"count_transactions\"))\n",
    "\n",
    "count_transactions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average transaction amount (/2)\n",
    "<span style=\"background-color: yellow;\">Find the average transaction amount per district in Paris, the columns must be \"district\" and \"avg_amount\".</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|district|        avg_amount|\n",
      "+--------+------------------+\n",
      "|       1| 4.301764246339528|\n",
      "|       2| 4.480481584776363|\n",
      "|       3| 4.305446529342117|\n",
      "|       4| 4.117026393682926|\n",
      "|       5|  4.11636519485262|\n",
      "|       6| 4.091528713153557|\n",
      "|       7| 4.358567822283758|\n",
      "|       8|3.7411084164675112|\n",
      "|       9| 3.285424385216695|\n",
      "|      10|3.0349363138361745|\n",
      "|      11|3.0225273033470357|\n",
      "|      12|2.2972604344204712|\n",
      "|      13|1.9482355792491894|\n",
      "|      14| 2.054451960621803|\n",
      "|      15|1.9789072250383324|\n",
      "|      16|2.3930864311867337|\n",
      "|      17|2.3881802450173786|\n",
      "|      18|1.9813573437728245|\n",
      "|      19|1.6529570147163235|\n",
      "|      20|1.7255606331221356|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "avg_amount = [district: bigint, avg_amount: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[district: bigint, avg_amount: double]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avg_amount = parkmeter_transactions.groupBy(\"district\").agg(avg(\"amount\").alias(\"avg_amount\"))\n",
    "\n",
    "avg_amount.orderBy(\"district\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow;\">Find the average transaction amount per area in Paris, the columns must be \"area\" and \"avg_amount\".</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|area|        avg_amount|\n",
      "+----+------------------+\n",
      "| 20E|1.8331724677103984|\n",
      "| 17R|2.0945348911531583|\n",
      "| 13G|1.8544097995547602|\n",
      "| 17H|2.8468915847870147|\n",
      "| 14G|1.7036216822272703|\n",
      "| 16H|4.4431372571414265|\n",
      "| 12K|1.6725680547076067|\n",
      "|  2E| 4.480481584776363|\n",
      "| 16W| 1.554992893761908|\n",
      "| 20L|1.6929231895876082|\n",
      "| 11G|3.2125187141951104|\n",
      "| 17F|2.1540502423191694|\n",
      "| 11L|2.8811642590074285|\n",
      "| 15M|1.6813064576330332|\n",
      "| 19L|1.5279515326018853|\n",
      "| 16I| 4.223896085728048|\n",
      "| 20H| 1.755981560666388|\n",
      "| 18H| 1.874756749774015|\n",
      "| 14N|2.7749364197021045|\n",
      "|  7E| 4.527142202837942|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "avg_amount = [area: string, avg_amount: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[area: string, avg_amount: double]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avg_amount = parkmeter_transactions.groupBy(\"area\").agg(avg(\"amount\").alias(\"avg_amount\"))\n",
    "\n",
    "avg_amount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, rename the notebook with the following format `\"evaluation_<name>.ipynb\"`. Then, send it by email at `francois@univalence.io; bernarith@univalence.io`. Wait for the examiners notebook approval before leaving the class."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
